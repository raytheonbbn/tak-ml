/*
 * OpenAPI definition
 * No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)
 *
 * OpenAPI spec version: v0
 * 
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 * Do not edit the class manually.
 */

package com.bbn.takml_server.client;

import com.bbn.takml_server.client.models.ErrorResponse;
import com.bbn.takml_server.client.models.InferenceRequest;
import com.bbn.takml_server.client.models.InferenceResponse;
import com.bbn.takml_server.client.models.ModelMetadataResponse;
import com.bbn.takml_server.client.models.ServerMetadataResponse;
import org.junit.Test;
import org.junit.Ignore;


import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;


/**
 * API tests for ModelExecutionApi
 */
@Ignore
public class ModelExecutionApiTest {

    private final ModelExecutionApi api = new ModelExecutionApi();

    /**
     * Model Version Metadata
     *
     * Retrieves metadata for a specific version of a model. 
     *
     * @throws Exception
     *          if the Api call fails
     */
    @Test
    public void getModelVersionMetadataTest() throws Exception {
        String MODEL_NAME = null;
        String MODEL_VERSION = null;
        ModelMetadataResponse response = api.getModelVersionMetadata(MODEL_NAME, MODEL_VERSION);

        // TODO: test validations
    }
    /**
     * Model Version Ready
     *
     * The \&quot;model version ready\&quot; API indicates if a specific version of a model is ready for inference. 
     *
     * @throws Exception
     *          if the Api call fails
     */
    @Test
    public void getModelVersionReadyTest() throws Exception {
        String MODEL_NAME = null;
        String MODEL_VERSION = null;
        api.getModelVersionReady(MODEL_NAME, MODEL_VERSION);

        // TODO: test validations
    }
    /**
     * Server Metadata
     *
     * Retrieves metadata about the inference server. 
     *
     * @throws Exception
     *          if the Api call fails
     */
    @Test
    public void getServerMetadataTest() throws Exception {
        ServerMetadataResponse response = api.getServerMetadata();

        // TODO: test validations
    }
    /**
     * Server Live
     *
     * The \&quot;server live\&quot; API indicates if the inference server is running and able to handle requests. This can be used for Kubernetes liveness probes. 
     *
     * @throws Exception
     *          if the Api call fails
     */
    @Test
    public void getV2HealthLiveTest() throws Exception {
        api.getV2HealthLive();

        // TODO: test validations
    }
    /**
     * Server Ready
     *
     * The \&quot;server ready\&quot; API indicates if the inference server is ready to handle inference requests. This can be used for Kubernetes readiness probes. 
     *
     * @throws Exception
     *          if the Api call fails
     */
    @Test
    public void getV2HealthReadyTest() throws Exception {
        api.getV2HealthReady();

        // TODO: test validations
    }
    /**
     * Inference
     *
     * Performs inference using a specific version of a model. 
     *
     * @throws Exception
     *          if the Api call fails
     */
    @Test
    public void postModelVersionInferTest() throws Exception {
        InferenceRequest body = null;
        String MODEL_NAME = null;
        String MODEL_VERSION = null;
        InferenceResponse response = api.postModelVersionInfer(body, MODEL_NAME, MODEL_VERSION);

        // TODO: test validations
    }
}
